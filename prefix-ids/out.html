<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="keywords" content="Epistemic Rationality, Consistency, Veritism, Dominance, Epistemic Normativity, Reasons" />
  <title>Consistency, Obligations, and Accuracy-Dominance Vindications</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Consistency, Obligations, and Accuracy-Dominance Vindications</h1>
<p class="author">true</p>
</header>
<p>The normativity of the following formal coherence requirements is contentious:</p>
<div class="statement">
<p><strong>Belief Consistency</strong>. If A believes that P, it is false that A believes that <span class="math inline">¬</span>P.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
</div>
<div class="statement">
<p><strong>Credal Consistency</strong>. If A has a credence of X in P, then A has a credence of (1-X) in <span class="math inline">¬</span>P.</p>
</div>
<p>Do we fall under an obligation to satisfy these requirements?<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> Many philosophers like John Broome <span class="citation" data-cites="broome:2013">(2013, ch. 13)</span> are convinced that the above requirements are normative, but cannot find a satisfactory argument in favour of such a conclusion. Other philosophers are less optimistic. For instance, Niko Kolodny <span class="citation" data-cites="kolodny:2005 kolodny:2007 kolodny:2007a">(2005; 2007b; 2007a, 230–31)</span> has argued that there is no reason to be consistent. According to him, what matters from an epistemic point of view is acquiring true beliefs (or acquiring beliefs that are likely to be true on the evidence) and avoiding false beliefs (or avoiding beliefs that are likely to be false on the evidence). However, a perfectly consistent system of beliefs (or credences) can be entirely false, inaccurate or improbable on the evidence. So, consistency requirements are not normative, in the sense that one does not necessarily have a reason to be consistent.</p>
<p>Recently, a new strategy has emerged to vindicate the normativity of Consistency. This strategy relies on accuracy-dominance principles, which roughly say that if state <span class="math inline"><em>Y</em></span> is better than state <span class="math inline"><em>X</em></span> at every possible world, one ought to avoid state <span class="math inline"><em>X</em></span>. However, there is a weak and a strong interpretation of what is entailed by the accuracy-dominance arguments. According to the strong interpretation, accuracy-dominance arguments entail that one ought to be consistent. Joyce, for instance, argues that:</p>
<blockquote>
<p>It is thus established that degrees of belief that violate the laws of probability are invariably less accurate than they could be. Given that an epistemically rational agent will always strive to hold partial beliefs that are as accurate as possible, this vindicates the fundamental dogma of probabilism [according to which degrees of belief must make conformity to the axioms of probability]. <span class="citation" data-cites="joyce_jm:1998">(1998, 600)</span></p>
</blockquote>
<p>According to the weak interpretation, accuracy-dominance arguments merely entail that ought not to be inconsistent. Easwaran, for instance, says that “we can use dominance to <em>eliminate</em>” the inconsistent doxastic options <span class="citation" data-cites="easwaran:2016b">(2016, 826, emphasis added)</span>. In other words, dominance is here used to argue against inconsistency. Thus, we can make the following distinction between two views:</p>
<div class="statement">
<p><strong>Normativity+</strong>. Given the accuracy-dominance arguments, A ought to be consistent.</p>
</div>
<div class="statement">
<p><strong>Normativity-</strong>. Given the accuracy-dominance arguments, A ought not to be inconsistent.</p>
</div>
<p>This paper argues that, while accuracy-dominance arguments can vindicate Normativity-, they do not necessarily vindicate Normativity+. Specifically, accuracy-dominance arguments vindicate Normativity+ when supplemented with a contentious hypothesis concerning the relationship between reasons for and reasons against. Hence, accuracy-dominance arguments do not vindicate Normativity+ <em>on their own</em>.</p>
<p>In sec. <strong>¿sec:the-why-be-consistent-challenges?</strong>, I clarify the debate on the normativity of Consistency. In Sections <strong>¿sec:accuracy-dominance-and-consistency?</strong> and <strong>¿sec:truth-conduciveness-reasons-for-and-reasons-against?</strong>, I present two important arguments in the debate surrounding the normativity of Consistency: accuracy-dominance arguments and Kolodny’s objection from truth-conduciveness. Both arguments are veritistic: They assume that only true beliefs bear final epistemic value, and only false beliefs bear final epistemic disvalue. I argue that, under the assumption that veritism is true, the only way to make sense of both arguments is to make a distinction between Normativity+ and Normativity- (i.e. to deny that both views are coextensive). Then, I argue that accuracy-dominance arguments fail to vindicate Normativity+.</p>
<p>This is not necessarily bad news. In conclusion, I explain why this might be an occasion to adjust our expectations in the debate on the normativity of formal coherence requirements. Many people think that there is something bad or suboptimal with inconsistent combinations of attitudes. The mistake might have been to try to explain this assumption in terms of <em>an obligation to be consistent</em>. Being in a position to vindicate Normativity- while remaining neutral on Normativity+ could be advantageous in the debate on the normativity of formal coherence requirements.</p>
<h1 id="PREFIXthe-why-be-consistent-challenges">The “Why-Be-Consistent?” Challenges</h1>
<p>There are many putative explanations of why one ought to have <em>some</em> consistent combinations of beliefs. They stem from the normative authority of truth, knowledge or reasons, as in the following:</p>
<div class="statement">
<p><strong>Truth Vindication</strong>. One ought to believe <span class="math inline"><em>P</em></span> if and only if P. Truth is consistent (or: Inconsistent propositions cannot be true simultaneously). So, one ought to have some consistent combinations of beliefs (e.g. the true ones).</p>
</div>
<div class="statement">
<p><strong>Knowledge Vindication</strong>. One is epistemically permitted to believe P if and only if one is in a position to know that P. Knowledge is consistent (or: Propositions that one is in a position to know cannot be inconsistent with each other). So, one is only epistemically permitted to believe consistent combinations of beliefs.</p>
</div>
<div class="statement">
<p><strong>Reasons Vindication</strong>. One is epistemically permitted to believe <span class="math inline"><em>P</em></span> if and only if one has sufficient epistemic reason to believe P. One never has sufficient epistemic reason to believe <span class="math inline"><em>P</em></span> and sufficient epistemic reason to disbelieve <span class="math inline"><em>P</em></span> simultaneously. So, one is only epistemically permitted to believe consistent combinations of beliefs.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
</div>
<p>Philosophers like <span class="citation" data-cites="broome:2013">Broome (2013)</span> and others are worried that the above putative vindications do not fully vindicate the normativity of Consistency. Some consistent combinations of beliefs may include some false, unjustified or unreasonable beliefs. Even if consistent agents sometimes believe propositions that are false, unjustified or unreasonable, it seems that they satisfy a distinct obligation to have consistent beliefs (e.g. an obligation that does not boil down to truth, knowledge or reasons). In other words, perhaps the agent is unjustified, mistaken or unreasonable, but one could still say: <em>At least he or she is consistent</em>. Here, the putative obligation to be consistent will not come from truth, knowledge or reasons.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p>So, according to some philosophers, the above vindications are somehow incomplete. Perhaps we can easily argue that agents ought to have <em>some</em> consistent combinations of beliefs, but finding a vindication of Consistency that covers all the possible consistent combinations of beliefs has proved to be a difficult task.</p>
<p>It should also be noted that the normativity of Consistency is part of a broader debate on the normativity of <em>structural rationality</em>. Structural rationality allegedly requires of agents not to be incoherent — for example, not to be akratic, not to have intransitive preferences, and so forth <span class="citation" data-cites="worsnip:2018b worsnip:2018">(Worsnip 2018a, 2018b)</span>. So, in addition to Consistency, there are other putative structural requirements of rationality, like:</p>
<div class="statement">
<p><strong>Inter-Level Coherence.</strong> Rationality requires that, if A believes that he or she has sufficient epistemic reason to believe P, then A believes that P.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
</div>
<div class="statement">
<p><strong>Instrumental Principle</strong>. Rationality requires that, if A intends to <span class="math inline"><em>ϕ</em></span>, and A believes that <span class="math inline"><em>ψ</em></span>-ing is a necessary means to <span class="math inline"><em>ϕ</em></span>-ing, then A intends to <span class="math inline"><em>ψ</em></span>.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
</div>
<p>Broome and others have tried to find compelling arguments for the claim that <em>structural rationality</em> has normative authority. However, structural rationality is neutral on whether one’s beliefs should be true, reasonable or amount to knowledge. Some entirely false and unreasonable belief systems can satisfy the requirements of structural rationality. So, at least given the agenda of these philosophers, a good vindication of the normativity of Consistency should cover the cases in which one’s beliefs are false or unreasonable.</p>
<p>An interesting feature of accuracy-dominance arguments is that they remain neutral on whether one’s beliefs should be true, reasonable or amount to knowledge. They focus on what is wrong with having some combinations of beliefs, regardless of the substantive properties of such beliefs.</p>
<h1 id="PREFIXaccuracy-dominance-and-consistency">Accuracy-Dominance and Consistency</h1>
<p>Accuracy-dominance arguments for vindicating the normativity of Consistency come from decision theory and rely on the following principle:</p>
<div class="statement">
<p><strong>Strong Dominance</strong>. If an available state <span class="math inline"><em>X</em></span> is strongly dominated by an available state <span class="math inline"><em>Y</em></span> at every possible world, in the sense that state <span class="math inline"><em>Y</em></span> is better or has more value than state <span class="math inline"><em>X</em></span> at every possible world, one ought to avoid state <span class="math inline"><em>X</em></span>.</p>
</div>
<p>Strong Dominance has been used to vindicate probabilism, the view roughly stating that an agent’s rational credences should satisfy the probability axioms. With respect to some inaccuracy measures such as the Brier score, probabilistically inconsistent agents have access to a credence function that is less inaccurate (and thus less epistemically disvaluable) at every possible world <span class="citation" data-cites="joyce_jm:1998 leitgeb-pettigrew:2010 pettigrew:2016">(Joyce 1998; Leitgeb and Pettigrew 2010; Pettigrew 2016a)</span>.</p>
<p>For the sake of simplicity, I will leave aside dominance for credence and focus on dominance for belief (these arguments have the same structure, but dominance arguments for belief are more accessible).</p>
<p>There is a plausible explanation of why inconsistent combinations of beliefs are strongly dominated. An agent can take different doxastic attitudes towards <span class="math inline"><em>P</em></span>, as in the following:</p>
<ol type="i">
<li><p>Believing <span class="math inline"><em>P</em></span> and not disbelieving <span class="math inline"><em>P</em></span>,</p></li>
<li><p>Disbelieving <span class="math inline"><em>P</em></span> and not believing <span class="math inline"><em>P</em></span>,</p></li>
<li><p>Neither believing nor disbelieving <span class="math inline"><em>P</em></span>,</p></li>
<li><p>Believing <span class="math inline"><em>P</em></span> and disbelieving <span class="math inline"><em>P</em></span>.</p></li>
</ol>
<p>The question is whether (iv) is strongly dominated. To answer this question, we need to determine the epistemic value of (iv) at every possible world. In veritistic frameworks, only true beliefs have final epistemic value and only false beliefs have final epistemic disvalue. Accordingly, <span class="math inline"><em>T</em></span> is the epistemic value of having a true belief (for <span class="math inline"><em>T</em> &gt; 0</span>), F is the epistemic disvalue of having a false belief (for <span class="math inline"><em>F</em> &lt; 0</span>), and the epistemic value of not believing <span class="math inline"><em>P</em></span> (or not disbelieving <span class="math inline"><em>P</em></span>) is 0.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> Finally, assume that <span class="math inline"><em>T</em> ← <em>F</em></span>, which amounts to endorsing a conservative account of epistemic value. The conservative constraint on epistemic value is plausible.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> As Dorst says:<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<blockquote>
<p>[An epistemically rational agent] will be doxastically conservative… Why? Well here’s a fair coin — does she believe it’ll land heads? Or tails? Or both? Or neither? Clearly neither. But if she cared more about seeking truth than avoiding error, why not believe both? She’d then be guaranteed to get one truth and one falsehood, and so be more accurate than if she believed neither… Upshot: we impose a <em>Conservativeness</em> constraint to capture the sense in which Rachael has ‘more to lose’ in forming a belief than she does to gain. <span class="citation" data-cites="dorst:2019">(2019, 11)</span></p>
</blockquote>
<p>Then, we can determine the possible values of each option at every possible world. Since the value of these options is solely determined by P’s truth value, we need to consider the worlds in which <span class="math inline"><em>P</em></span> is true and the worlds in which <span class="math inline"><em>P</em></span> is false, as in the following table:</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Table 1.</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Doxastic options / possible world</strong></td>
<td><strong><span class="math inline"><em>P</em></span> is true</strong></td>
<td><strong><span class="math inline"><em>P</em></span> is false</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">Believing <span class="math inline"><em>P</em></span> and not disbelieving <span class="math inline"><em>P</em></span></td>
<td><span class="math inline"><em>T</em></span></td>
<td><span class="math inline"><em>F</em></span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Disbelieving <span class="math inline"><em>P</em></span> and not believing <span class="math inline"><em>P</em></span></td>
<td><span class="math inline"><em>F</em></span></td>
<td><span class="math inline"><em>T</em></span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Neither believing nor disbelieving <span class="math inline"><em>P</em></span></td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Believing <span class="math inline"><em>P</em></span> and disbelieving <span class="math inline"><em>P</em></span></td>
<td><span class="math inline"><em>T</em> + <em>F</em></span></td>
<td><span class="math inline"><em>T</em> + <em>F</em></span></td>
</tr>
</tbody>
</table>
<p>Finally, in accordance with Table 1, we can conclude that inconsistent combinations of beliefs are strongly dominated. The following reasoning supports such a conclusion:</p>
<ol type="1">
<li><p><span class="math inline"><em>T</em> ← <em>F</em></span> (conservative assumption). Accordingly, <span class="math inline"><em>T</em> + <em>F</em> &lt; 0</span>.</p></li>
<li><p>Following (1) and Table 1, believing <span class="math inline"><em>P</em></span> and disbelieving <span class="math inline"><em>P</em></span> simultaneously has an epistemic value of less than 0 at every possible world.</p></li>
<li><p>However, following Table 1, neither believing nor disbelieving <span class="math inline"><em>P</em></span> has an epistemic value of 0 at every possible world.</p></li>
</ol>
<ol start="3" type="A">
<li>Therefore, following (2) and (3), inconsistent combinations of beliefs such as believing <span class="math inline"><em>P</em></span> and disbelieving <span class="math inline"><em>P</em></span> are strongly dominated: another available option (neither believing nor disbelieving <span class="math inline"><em>P</em></span>) is more valuable at every possible world.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></li>
</ol>
<p>Hence, one ought to avoid being inconsistent.</p>
<h1 id="PREFIXtruth-conduciveness-reasons-for-and-reasons-against">Truth-Conduciveness, Reasons For and Reasons Against</h1>
<h2 id="PREFIXkolodnys-objection-from-truth-conduciveness">Kolodny’s Objection From Truth-Conduciveness</h2>
<p>The above argument states that inconsistent combinations of beliefs are dominated, which means that one ought not to be inconsistent. Naturally, this seems to suggest that one ought to be consistent. But this equivalence is less obvious than it seems.</p>
<p>To see why, consider Kolodny’s argument against the normativity of Consistency. According to him, one does not necessarily have an epistemic reason to be consistent. Rather, what matters from an epistemic point of view is having true beliefs and avoiding false beliefs, and satisfying Consistency does not guarantee a better ratio of true to false beliefs. In fact, some perfectly consistent sets of beliefs are entirely false (or improbable on the evidence). Kolodny summarizes his argument in the following way:</p>
<blockquote>
<p>From the standpoint of theoretical deliberation — which asks ‘What ought I to believe?’—what ultimately matters is simply what is likely to be true, given what there is to go on. […] [But] formal coherence may as soon lead one away from, as toward, the true and the good. Thus, if someone asks from the deliberative standpoint ‘What is there to be said for making my attitudes formally coherent as such?’ there seems, on reflection, no satisfactory answer. <span class="citation" data-cites="kolodny:2007a">(2007a, 231)</span></p>
</blockquote>
<p>In other words, if one merely satisfies Consistency, one is not more likely to end up forming true beliefs and avoiding false beliefs. So, the mere satisfaction of Consistency does not improve one’s ratio of true to false beliefs. In view of the foregoing, Kolodny thinks that it is false that one falls under an obligation to be consistent.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></p>
<h2 id="PREFIXcomparing-the-objection-from-truth-conduciveness-and-accuracy-dominance-arguments">Comparing the Objection from Truth-Conduciveness and Accuracy-Dominance Arguments</h2>
<p>Kolodny argues that there is no reason to be consistent. His argument relies on the fact that being consistent does not guarantee a good ratio of true to false beliefs. By way of contrast, accuracy-dominance arguments suggest that there is good reason not to be inconsistent. If one is inconsistent, one is strongly dominated, in the sense that one has access to a better option at every possible world. For instance, if one believes <span class="math inline"><em>P</em></span> and disbelieves <span class="math inline"><em>P</em></span> simultaneously, one will necessarily improve one’s situation by neither believing nor disbelieving P.</p>
<p>Accuracy-dominance arguments and Kolodny’s objection from truth-conduciveness are both veritistic.<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> Indeed, they presuppose that only true beliefs bear final epistemic value, and only false beliefs bear final epistemic disvalue. Nevertheless, such arguments apparently support incompatible conclusions concerning the normativity of Consistency: Kolodny argues that veritism entails the denial of the normativity of Consistency, whereas accuracy-dominance arguments support the normativity of Consistency. This is puzzling.</p>
<p>Perhaps Kolodny and accuracy-dominance theorists do not endorse the same version of veritism. Veritism says that only true beliefs have final epistemic value, and only false beliefs have final epistemic disvalue. However, when it comes to epistemic obligations and permissions, these assumptions concerning epistemic value might translate in many different ways. For instance, perhaps agents ought to maximize their <em>total</em> epistemic score (e.g. the total balance of epistemic value they get from their doxastic states), or perhaps agents ought to maximize their <em>expected</em> epistemic score. For clarity, consider the following example: Suppose <span class="math inline"><em>P</em></span> is very likely relative to a body of evidence E. But as it happens, <span class="math inline"><em>P</em></span> is false. Then, believing <span class="math inline"><em>P</em></span> (or having a high credence in P) might maximize expected epistemic value with respect to E. But disbelieving <span class="math inline"><em>P</em></span> (or having a low credence in P) will maximize epistemic value <em>tout court</em>.</p>
<p>Yet, it is implausible that a difference in how Joyce and Kolodny understand veritism is the reason why they disagree. Kolodny’s argument can be reformulated in many different ways. Consider the following possibilities: (i) Suppose agents ought to maximize <em>expected</em> accuracy. Then, Kolodny could say: Some consistent combinations of beliefs can minimize expected accuracy (believing the most improbable propositions can be consistent). (ii) Suppose agents ought to optimize their ratio of true to false beliefs. Then, Kolodny could argue that some agents with a very bad ratio of true to false beliefs are consistent. (iii) Suppose agents ought to maximize <em>total</em> accuracy. Then, Kolodny could say: Some consistent combinations of beliefs can minimize accuracy (believing false propositions only can be consistent). As we can see, Kolodny’s objection is malleable.<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a></p>
<p>Another possibility is that Kolodny and accuracy-first theorists have a different understanding of what “ought” means. We can make a distinction between normativity in the rule-following sense (as in: Relative to domain D, A ought to X) and normativity in the reason-involving sense (as in: A has a reason to X).<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> For example, the rules of etiquette require of agents to be polite, but agents might lack a reason to be polite. By way of analogy with the rules of etiquette, perhaps accuracy-first theorists are merely interested in arguing that the rules of rationality require consistency. This would be compatible with Kolodny’s view — namely, that agents do not have a reason to be consistent. Both views would then be compatible with each other.</p>
<p>It is true that accuracy-first theorists see Consistency as a demand of rationality. However, it is implausible that accuracy-first theorists are <em>merely</em> concerned with normativity in the rule-following sense. Accuracy-first theorists like Joyce tie norms of rationality to epistemic value, as in the following:</p>
<div class="statement">
<p><strong>The Norm of Truth</strong>. An epistemically rational agent must strive to hold a system of full beliefs that strikes the best attainable overall balance between the epistemic good of fully believing truths and the epistemic evil of fully believing falsehoods <span class="citation" data-cites="joyce_jm:1998">(Joyce 1998, 577)</span>.</p>
</div>
<div class="statement">
<p><strong>The Norm of Gradational Accuracy.</strong> An epistemically rational agent must evaluate partial beliefs on the basis of their gradational accuracy, and she must strive to hold a system of partial beliefs that, in her best judgment, is likely to have an overall level of gradational accuracy at least as high as that of any alternative system she might adopt <span class="citation" data-cites="joyce_jm:1998">(Joyce 1998, 579)</span>.</p>
</div>
<p>Satisfying the requirements of rationality is different from, say, satisfying the requirements of etiquette. The former has a privileged relationship to value. Epistemically rational agents want to optimize their overall balance of epistemic value. Accordingly, it would be surprising that Joyce and others are merely concerned with normativity in the rule-following sense. Specifically, it would be surprising that, while rationality has some sort of privileged relationship to value, it is merely normative in the rule-following sense.<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a></p>
<p>Under the assumption that Kolodny and accuracy-dominance theorists agree upon a specific version of veritism and the meaning of “ought,” the natural reaction is to think that at least one of the above arguments is mistaken — either the objection from truth-conduciveness is inconclusive, or accuracy-dominance arguments fail. After all, how can there be no reason to be consistent and reasons against being inconsistent? If there is something wrong with being inconsistent, there must be something good with being consistent!</p>
<p>However, this natural reaction presupposes that there is always a connection between (i) reasons for being consistent (as in Normativity+) and (ii) reasons against being inconsistent (as in Normativity-). Call this the Coextensivity Thesis, as in the following:</p>
<div class="statement">
<p><strong>Coextensivity Thesis</strong>. Arguments in favour of Normativity- count as arguments in favour of Normativity+ (and vice versa).</p>
</div>
<p>Those who endorse the Coextensivity Thesis think that (i) and (ii) express the same normative relation.</p>
<p>If the Coextensivity Thesis were correct, then Kolodny’s objection from truth-conduciveness would be inconclusive. Under the assumption that the Coextensivity Thesis is correct, two kinds of considerations can vindicate the view that one ought to be consistent — namely, reasons be consistent and reasons against being inconsistent. Kolodny argues for the <em>absence</em> of reasons in favour of being consistent. But if the Coextensivity Thesis is correct, <em>such considerations are just half of the story</em>. We also need to consider whether there are reasons against being inconsistent in the balance, since they count as reasons for being consistent. Accuracy-dominance arguments entail that one ought not to be inconsistent. So, even if Kolodny is right that there is no reason to satisfy Consistency, this does not entail that it is false that one ought to be consistent. Insofar as there are arguments against inconsistency (as suggested by accuracy-dominance arguments), there is a reason to be consistent.</p>
<p>However, if the Coextensivity Thesis is false, then accuracy-dominance arguments are compatible with the objection from truth-conduciveness. Here is why. Kolodny argues that there is no reason to be consistent: he denies that one ought to be consistent, as in Normativity+. However, if the Coextensivity Thesis is false, we can deny Normativity+ without denying Normativity-. In other words, even if it is false that one ought to be consistent, perhaps one ought not to be inconsistent. The same goes for accuracy-dominance arguments. According to such arguments, inconsistent combinations of beliefs are dominated. So, one ought not to be inconsistent. But if the Coextensivity Thesis is false, this does not entail that one ought to be consistent.</p>
<h2 id="PREFIXreasons-to-be-consistent-and-the-coextensivity-thesis">Reasons to be Consistent and the Coextensivity Thesis</h2>
<p>So, is the Coextensivity Thesis true? This depends on what “a reason to be consistent” means. Suppose, like Kolodny, that “a reason to be consistent” concerns each individual consistent option one has (see §3.1). That is, suppose that “a reason to be consistent” means something like “a consideration that counts in favour of <em>each</em> individual consistent options one has.” For Kolodny, nothing can be said in favour of some consistent combinations of attitudes. So, under this interpretation of what “a reason to be consistent” means, we do not necessarily have a reason to be consistent.</p>
<p>Relative to this interpretation of what “a reason to be consistent” means, the Coextensitivity Thesis does not seem plausible. For reasons found in <span class="citation" data-cites="snedegar_j:2018">Snedegar (2018)</span>, we can make a distinction between reasons for Consistency (as in Normativity+) and reasons against inconsistency (as in Normativity-). The distinction comes from the following account of reasons for and reasons against endorsed by Snedegar:</p>
<blockquote>
<p>My view puts a strong condition on reasons for and a weak condition on reasons against. For some objective to provide a reason for an option, that option has to do the best with respect to the objective. For some objective to provide a reason against an option, that option only has to do worse than some alternative. <span class="citation" data-cites="snedegar_j:2018">(2018, 737)</span></p>
</blockquote>
<p>Snedegar roughly argues that the problem with views that lump together reasons against and reasons for is that there can be good reasons not to <span class="math inline"><em>ϕ</em></span>, even if there are worse alternatives to <span class="math inline"><em>ϕ</em></span>-ing.<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a> For instance, suppose that I am trying to decide what to drink. I might have conclusive reason not to drink gin, but this does not entail that I have a reason to drink any beverage that isn’t gin. I should definitely not drink petrol, even if petrol isn’t gin. This is compatible with my having conclusive reason not to drink gin.</p>
<p>Snedegar’s observation sits well with accuracy-dominance arguments discussed in Sec. <strong>¿sec:accuracy-dominance-and-consistency?</strong>. Indeed, recall the options agents have in table 1:</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Table 1.</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Doxastic options / possible world</strong></td>
<td><strong>P is true</strong></td>
<td><strong>P is false</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">Believing <span class="math inline"><em>P</em></span> and not disbelieving <span class="math inline"><em>P</em></span></td>
<td>T</td>
<td>F</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Disbelieving <span class="math inline"><em>P</em></span> and not believing <span class="math inline"><em>P</em></span></td>
<td>F</td>
<td>T</td>
</tr>
<tr class="even">
<td style="text-align: left;">Neither believing nor disbelieving <span class="math inline"><em>P</em></span></td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Believing <span class="math inline"><em>P</em></span> and disbelieving <span class="math inline"><em>P</em></span></td>
<td>T+F</td>
<td>T+F</td>
</tr>
</tbody>
</table>
<p>Clearly, there is conclusive reason not to go for the inconsistent option, since neither believing nor disbelieving <span class="math inline"><em>P</em></span> is better than being inconsistent at every possible world. However, this does not entail that there is a reason in favour of every alternative to the inconsistent option. For instance, disbelieving <span class="math inline"><em>P</em></span> when <span class="math inline"><em>P</em></span> is true (or believing <span class="math inline"><em>P</em></span> when P is false) is worse than being inconsistent. So, as in the gin and petrol case, reasons against inconsistency are logically weaker than reasons for Consistency.</p>
<p>This suggests that accuracy-dominance arguments do not vindicate Normativity+ on their own. Of course, when combined with the Coextensivity Thesis, these arguments support Normativity+. But Kolodny’s interpretation of what “a reason to be consistent” means conflicts with the Coextensivity Thesis. So, while accuracy-dominance arguments support Normativity-, it is an open question whether they also support Normativity+.</p>
<p>Here is a response to my argument on behalf of the accuracy-dominance theorist. We can regroup the consistent options in table 1 under a single option. Call this the consistent option. With respect to the consistent option, Snedegar’s distinction does not apply. If there is conclusive reason not to go for the inconsistent option, and the only option left is the “regrouped” consistent option, then reasons against inconsistency favour the consistent option. So, could there be a sense in which the Coextensivity Thesis is true?<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a></p>
<p>My response to this objection goes as follows. This way of framing the problem cannot make sense of Kolodny’s objection concerning some consistent options. <em>There is something wrong with some consistent combinations of beliefs</em> — some consistent combinations of beliefs are entirely wrong or improbable on the evidence. Kolodny is right to point out that nothing can be said in favour of these combinations of attitudes. The only way to make sense of Kolodny’s objection is <em>not</em> to regroup all the consistent options under a single label, precisely because relevant normative distinctions can (and should) be made between some consistent options.</p>
<p>At best, this reply shows that, under a different interpretation of what “a reason to be consistent” means, the Coextensivity Thesis is true. But Kolodny’s argument still succeeds relative to another interpretation of this expression. When Kolodny discusses the normativity of Consistency, he discusses the normativity of the individual consistent options one has, including the ones that are entirely wrong or improbable on the evidence. The accuracy-dominance theorist can claim that one ought to be consistent, but that is simply because the expression “one ought to be consistent” here refers to something logically weaker than what Kolodny has in mind.<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a></p>
<h2 id="PREFIXan-escape-route-for-the-accuracy-dominance-theorist">An Escape Route for the Accuracy-Dominance Theorist?</h2>
<p>The accuracy-dominance theorist could then offer the following objection. Suppose there is an accuracy-dominance argument against one’s attitudes. Accordingly, one can identify at least one collection of attitudes that veritistically dominates one’s current state. If agents can identify at least one set of attitudes that is better than their current state, then they have a reason to take the dominating set of attitudes, which will be consistent. Doesn’t this support the view according to which one ought to be consistent? If agents ought to take dominating combinations of beliefs, and such combinations of beliefs are consistent, then this seems to entail that agents ought to be consistent.<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a></p>
<p>This objection carries weight depending on what accuracy-dominance arguments prove. Let me explain.</p>
<p>Suppose the contender is right. Then, accuracy-dominance vindications are akin to the Truth Vindication, the Knowledge Vindication or the Reasons Vindication discussed in sec. <strong>¿sec:the-why-be-consistent-challenges?</strong>. If one has inconsistent combinations of beliefs (say, one believes <span class="math inline"><em>P</em></span> and also believes <span class="math inline">¬</span>P), the Truth Vindication says that agents ought to maintain the true one (and abandon the false one), the Knowledge Vindication says that agents are only permitted to maintain the known one, and the Reasons Vindication says that agents are only permitted to maintain the reasonable one (and ought to abandon the <em>unreasonable</em> one). In any case, satisfying such norms means that agents will cease entertaining inconsistent combinations of beliefs.</p>
<p>The contender makes a similar point. If one has inconsistent combinations of beliefs, one should go for the option dominating inconsistent combinations of beliefs. But if that is right, the accuracy-dominance argument merely entails that agents ought (or have reasons) to have <em>some</em> combinations of beliefs, not <em>any</em> consistent combination of beliefs. In other words, the argument leaves out some consistent combinations of beliefs.</p>
<p>This brings us back to the discussion in Sec. <strong>¿sec:the-why-be-consistent-challenges?</strong>. What do we expect from a good vindication of the normativity of Consistency? For many philosophers, a good vindication of Consistency should cover all the possible consistent combinations of beliefs. If the contender is right, then accuracy-dominance arguments can explain the significance of some consistent combinations of beliefs — namely, the dominating ones. But this is not what we were looking for. The explanation should apply to <em>all</em> the consistent combination of beliefs. To be clear: Some philosophers might not be interested in this specific interpretation of the “Why-Be-Consistent” debate. It should be clear that, with respect to other understandings of the question, the contender is right.</p>
<h1 id="PREFIXconclusion-and-implications-in-the-debate-on-the-normativity-of-structural-rationality">Conclusion and Implications in the Debate On The Normativity of Structural Rationality</h1>
<p>This paper supports the view that there are two theses concerning the normativity of Consistency: Normativity+ and Normativity-. While accuracy-dominance arguments support Normativity-, they might not necessarily support Normativity+. This is so, because the Coextensivity Thesis might be false. In fact, one way to reconcile Kolodny’s objection from truth-conduciveness with accuracy-dominance arguments is to deny the Coextensivity Thesis.</p>
<p>These clarifications concerning Normativity+ and Normativity- allow us to rethink the debate on the normativity of structural rationality. Indeed, a popular strategy for arguing against the normativity of structural rationality is to point out that there is no reason to satisfy some specific rational requirements (such as Consistency). Kolodny’s objection from truth-conduciveness is a good illustration of such arguments. These arguments are compelling if we focus on Normativity+. But this might be a mistake. Perhaps that, when it comes to formal requirements like Consistency, the only view we should try to vindicate is Normativity-.</p>
<p>The argument of this paper allows us to make sense of some pre-theoretically correct assumptions structural requirements of epistemic rationality such as Consistency. Plausibly, there is something wrong, suboptimal or disvaluable with inconsistent combinations of beliefs. The mistake might have been to try to explain this assumption in terms of <em>an obligation to be consistent</em>. But if I am right, we might only be able to explain this assumption in terms of <em>an obligation not to be inconsistent</em>. Hence, requirements like Consistency might merely be normative in a weak sense.</p>
<p>The good news is that we can now make sense of such a possibility. If the Coextensivity Thesis is false, it makes perfect sense to say that one ought not to be inconsistent without also saying that one ought to be consistent. There might not be something good with being structurally rational, but it seems patently clear that there is something bad with being structurally irrational.</p>
<h1 class="unnumbered" id="PREFIXreferences">References</h1>
<div id="PREFIXrefs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="PREFIXref-debona_g-staffel:2018" class="csl-entry" role="doc-biblioentry">
Bona, Glauber de, and Julia Staffel. 2018. <span>“Why Be (Approximately) Coherent?”</span> <em>Analysis</em> 78 (3): 405–15. <a href="https://doi.org/10.1093/analys/anx159">https://doi.org/10.1093/analys/anx159</a>.
</div>
<div id="PREFIXref-broome:2013" class="csl-entry" role="doc-biblioentry">
Broome, John A. 2013. <em>Rationality Through Reasoning</em>. Oxford: Wiley-Blackwell.
</div>
<div id="PREFIXref-coates_a:2012" class="csl-entry" role="doc-biblioentry">
Coates, Allen. 2012. <span>“Rational Epistemic Akrasia.”</span> <em>American Philosophical Quarterly</em> 49 (2): 113–24.
</div>
<div id="PREFIXref-daoust_mk:2020" class="csl-entry" role="doc-biblioentry">
Daoust, Marc-Kevin. 2020. <span>“The Explanatory Role of Consistency Requirements.”</span> <em>Synthese</em> 197: 4551–69. <a href="https://doi.org/10.1007/s11229-018-01942-8">https://doi.org/10.1007/s11229-018-01942-8</a>.
</div>
<div id="PREFIXref-dorst:2019" class="csl-entry" role="doc-biblioentry">
Dorst, Kevin. 2019. <span>“Lockeans Maximize Expected Accuracy.”</span> <em>Mind</em> 128 (509): 175–211. <a href="https://doi.org/10.1093/mind/fzx028">https://doi.org/10.1093/mind/fzx028</a>.
</div>
<div id="PREFIXref-easwaran:2016b" class="csl-entry" role="doc-biblioentry">
Easwaran, Kenny. 2016. <span>“Dr. Truthlove or: How <span>I</span> Learned to Stop Worrying and Love Bayesian Probabilities.”</span> <em>No<span>û</span>s</em> 50 (4): 816–53. <a href="https://doi.org/10.1111/nous.12099">https://doi.org/10.1111/nous.12099</a>.
</div>
<div id="PREFIXref-easwaran-fitelson:2015" class="csl-entry" role="doc-biblioentry">
Easwaran, Kenny, and Branden Fitelson. 2015. <span>“Accuracy, Coherence, and Evidence.”</span> In <em>Oxford Studies in Epistemology</em>, edited by Tamar Szabó Gendler and John Hawthorne, V:61–96. Oxford: Oxford University Press.
</div>
<div id="PREFIXref-fitelson:2016" class="csl-entry" role="doc-biblioentry">
Fitelson, Branden. 2016. <span>“Coherence.”</span> <a href="http://fitelson.org/coherence/coherence_duke.pdf">http://fitelson.org/coherence/coherence_duke.pdf</a>.
</div>
<div id="PREFIXref-goldman_ai:2015a" class="csl-entry" role="doc-biblioentry">
Goldman, Alvin I. 2015. <span>“Reliabilism, Veritism, and Epistemic Consequentialism.”</span> <em>Episteme</em> 12 (2): 131–43. <a href="https://doi.org/10.1017/epi.2015.25">https://doi.org/10.1017/epi.2015.25</a>.
</div>
<div id="PREFIXref-greco_d:2014" class="csl-entry" role="doc-biblioentry">
Greco, Daniel. 2014. <span>“A Puzzle about Epistemic Akrasia.”</span> <em>Philosophical Studies</em> 167 (2): 201–19. <a href="https://doi.org/10.1007/s11098-012-0085-3">https://doi.org/10.1007/s11098-012-0085-3</a>.
</div>
<div id="PREFIXref-horowitz_s:2014a" class="csl-entry" role="doc-biblioentry">
Horowitz, Sophie. 2014. <span>“Epistemic Akrasia.”</span> <em>No<span>û</span>s</em> 48 (4): 718–44. <a href="https://doi.org/10.1111/nous.12026">https://doi.org/10.1111/nous.12026</a>.
</div>
<div id="PREFIXref-joyce_jm:1998" class="csl-entry" role="doc-biblioentry">
Joyce, James M. 1998. <span>“A Nonpragmatic Vindication of Probabilism.”</span> <em>Philosophy of Science</em> 65 (4): 575–603. <a href="https://doi.org/10.1086/392661">https://doi.org/10.1086/392661</a>.
</div>
<div id="PREFIXref-kiesewetter_b:2016a" class="csl-entry" role="doc-biblioentry">
Kiesewetter, Benjamin. 2016. <span>“You Ought to <span class="math inline"><em>ϕ</em></span> Only If You May Believe That You Ought to <span class="math inline"><em>ϕ</em></span>.”</span> <em>The Philosophical Quarterly</em> 66 (265): 760–82. <a href="https://doi.org/10.1093/pq/pqw012">https://doi.org/10.1093/pq/pqw012</a>.
</div>
<div id="PREFIXref-kiesewetter_b:2017" class="csl-entry" role="doc-biblioentry">
———. 2017. <em>The Normativity of Rationality</em>. Oxford: Oxford University Press.
</div>
<div id="PREFIXref-kolodny:2005" class="csl-entry" role="doc-biblioentry">
Kolodny, Niko. 2005. <span>“Why Be Rational?”</span> <em>Mind</em> 114 (455): 509–63. <a href="https://doi.org/10.1093/mind/fzi509">https://doi.org/10.1093/mind/fzi509</a>.
</div>
<div id="PREFIXref-kolodny:2007a" class="csl-entry" role="doc-biblioentry">
———. 2007a. <span>“How Does Coherence Matter?”</span> <em>Proceedings of the Aristotelian Society</em> 107: 229–63. <a href="https://doi.org/10.1111/j.1467-9264.2007.00220.x">https://doi.org/10.1111/j.1467-9264.2007.00220.x</a>.
</div>
<div id="PREFIXref-kolodny:2007" class="csl-entry" role="doc-biblioentry">
———. 2007b. <span>“State or Process Requirements?”</span> <em>Mind</em> 116 (462): 371–85. <a href="https://doi.org/10.1093/mind/fzm371">https://doi.org/10.1093/mind/fzm371</a>.
</div>
<div id="PREFIXref-lasonenaarnio:2020" class="csl-entry" role="doc-biblioentry">
Lasonen-Aarnio, Maria. 2020. <span>“Enkrasia or Evidentialism? Learning to Love Mismatch.”</span> <em>Philosophical Studies</em> 177: 597–632. <a href="https://doi.org/10.1007/s11098-018-1196-2">https://doi.org/10.1007/s11098-018-1196-2</a>.
</div>
<div id="PREFIXref-leitgeb-pettigrew:2010" class="csl-entry" role="doc-biblioentry">
Leitgeb, Hannes, and Richard Pettigrew. 2010. <span>“An Objective Justification of Bayesianism i: Measuring Inaccuracy.”</span> <em>Philosophy of Science</em> 77 (2): 201–35. <a href="https://doi.org/10.1086/651317">https://doi.org/10.1086/651317</a>.
</div>
<div id="PREFIXref-littlejohn:2018a" class="csl-entry" role="doc-biblioentry">
Littlejohn, Clayon. 2018. <span>“Stop Making Sense? On a Puzzle about Rationality.”</span> <em>Philosophy and Phenomenological Research</em> 96 (2): 257–72. <a href="https://doi.org/10.1111/phpr.12271">https://doi.org/10.1111/phpr.12271</a>.
</div>
<div id="PREFIXref-parfit:2011" class="csl-entry" role="doc-biblioentry">
Parfit, Derek. 2011. <em>On What Matters. Volume One</em>. Oxford: Oxford University Press.
</div>
<div id="PREFIXref-pettigrew:2013a" class="csl-entry" role="doc-biblioentry">
Pettigrew, Richard. 2013. <span>“Accuracy and Evidence.”</span> <em>Dialectica</em> 67 (4): 579–96. <a href="https://doi.org/10.1111/1746-8361.12043">https://doi.org/10.1111/1746-8361.12043</a>.
</div>
<div id="PREFIXref-pettigrew:2016" class="csl-entry" role="doc-biblioentry">
———. 2016a. <em>Accuracy and the Laws of Credence</em>. Oxford: Oxford University Press.
</div>
<div id="PREFIXref-pettigrew:2016c" class="csl-entry" role="doc-biblioentry">
———. 2016b. <span>“Jamesian Epistemology Formalised: An Explication of <span>‘the Will to Believe’</span>.”</span> <em>Episteme</em> 13 (3): 253–68. <a href="https://doi.org/10.1017/epi.2015.44">https://doi.org/10.1017/epi.2015.44</a>.
</div>
<div id="PREFIXref-snedegar_j:2018" class="csl-entry" role="doc-biblioentry">
Snedegar, Justin. 2018. <span>“Reasons for and Reasons Against.”</span> <em>Philosophical Studies</em> 175: 725–43. <a href="https://doi.org/10.1007/s11098-017-0889-2">https://doi.org/10.1007/s11098-017-0889-2</a>.
</div>
<div id="PREFIXref-steinberger_f:2019a" class="csl-entry" role="doc-biblioentry">
Steinberger, Florian. 2019. <span>“Accuracy and Epistemic Conservatism.”</span> <em>Analysis</em> 79 (4): 658–69. <a href="https://doi.org/10.1093/analys/any094">https://doi.org/10.1093/analys/any094</a>.
</div>
<div id="PREFIXref-titelbaum:2015" class="csl-entry" role="doc-biblioentry">
Titelbaum, Michael G. 2015. <span>“Rationality’s Fixed Point (or: In Defense of Right Reason).”</span> In <em>Oxford Studies in Epistemology</em>, edited by Tamar Szabó Gendler and John Hawthorne, V:253–94. Oxford: Oxford University Press.
</div>
<div id="PREFIXref-way_j:2010" class="csl-entry" role="doc-biblioentry">
Way, Jonathan. 2010. <span>“The Normativity of Rationality.”</span> <em>Philosophy Compass</em> 5 (12): 1057–68. <a href="https://doi.org/10.1111/j.1747-9991.2010.00357.x">https://doi.org/10.1111/j.1747-9991.2010.00357.x</a>.
</div>
<div id="PREFIXref-way_j:2013a" class="csl-entry" role="doc-biblioentry">
———. 2013. <span>“Intentions, Akrasia, and Mere Permissibility.”</span> <em>Organon F</em> 20 (4): 588–611.
</div>
<div id="PREFIXref-whiting_da:2010a" class="csl-entry" role="doc-biblioentry">
Whiting, Daniel. 2010. <span>“Should <span>I</span> Believe the Truth?”</span> <em>Dialectica</em> 64 (2): 213–24. <a href="https://doi.org/10.1111/j.1746-8361.2009.01204.x">https://doi.org/10.1111/j.1746-8361.2009.01204.x</a>.
</div>
<div id="PREFIXref-worsnip:2018b" class="csl-entry" role="doc-biblioentry">
Worsnip, Alex. 2018a. <span>“The Conflict of Evidence and Coherence.”</span> <em>Philosophy and Phenomenological Research</em> 96 (1): 3–44. <a href="https://doi.org/10.1111/phpr.12246">https://doi.org/10.1111/phpr.12246</a>.
</div>
<div id="PREFIXref-worsnip:2018" class="csl-entry" role="doc-biblioentry">
———. 2018b. <span>“What Is (In)coherence?”</span> In <em>Oxford Studies in Metaethics</em>, edited by Russ Shafer-Landau, XIII:184–206. Oxford: Oxford University Press.
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>This requirement is sometimes called “Pairwise Consistency”, as in <span class="citation" data-cites="easwaran:2016b">Easwaran (2016)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>See <span class="citation" data-cites="way_j:2010">Way (2010)</span> for an overview of this debate. See <span class="citation" data-cites="fitelson:2016">Fitelson (2016)</span> on epistemic teleology and coherence requirements. See <span class="citation" data-cites="debona_g-staffel:2018">Bona and Staffel (2018)</span> on accuracy and approximation of Bayesian requirements of probabilistic coherence. See also Pettigrew <span class="citation" data-cites="pettigrew:2013a pettigrew:2016">(2013, 2016a)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p><span class="citation" data-cites="kolodny:2007">Kolodny (2007b)</span> endorses this view. See <span class="citation" data-cites="daoust_mk:2020">Daoust (2020)</span> for discussion.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>In fact, <span class="citation" data-cites="broome:2013">Broome (2013, ch. 11)</span> is interested in the stronger claim that rationality is a <em>source</em> of normativity. So, he is not interested in offering a derivative vindication of consistency requirements, that is, a vindication of these requirements on other grounds (like truth, knowledge, or reasons). By contrast, dominance principles are often tied to rationality <span class="citation" data-cites="joyce_jm:1998">(see e.g. Joyce 1998)</span>.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p><span class="citation" data-cites="coates_a:2012">Coates (2012)</span> and <span class="citation" data-cites="lasonenaarnio:2020">Lasonen-Aarnio (2020)</span> have argued that responding correctly to one’s evidence sometimes entail believing “P, but I am irrational to believe P”, which is an incoherent combination of attitudes. They conclude that such incoherence is not necessarily irrational. See <span class="citation" data-cites="greco_d:2014">Greco (2014)</span>, <span class="citation" data-cites="horowitz_s:2014a">Horowitz (2014)</span>, <span class="citation" data-cites="kiesewetter_b:2016a">Kiesewetter (2016)</span>, <span class="citation" data-cites="littlejohn:2018a">Littlejohn (2018)</span>, <span class="citation" data-cites="titelbaum:2015">Titelbaum (2015)</span> and <span class="citation" data-cites="worsnip:2018b">Worsnip (2018a)</span> for various responses to this view.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>See, among others, <span class="citation" data-cites="broome:2013">Broome (2013, sec. 9.4)</span>, <span class="citation" data-cites="kiesewetter_b:2017">Kiesewetter (2017, ch. 10)</span> and <span class="citation" data-cites="way_j:2013a">Way (2013)</span> on the Instrumental Principle.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>I’m glossing over some inessential subtleties here. It is possible to assign a value to not believing <span class="math inline"><em>P</em></span> (or to withholding judgment on whether P), but ultimately, we would get exactly the same results. See <span class="citation" data-cites="easwaran:2016b">Easwaran (2016, sec. C)</span> and <span class="citation" data-cites="dorst:2019">Dorst (2019, 10n12)</span>.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>But this constraint might not stem from accuracy-first epistemology. See <span class="citation" data-cites="steinberger_f:2019a">Steinberger (2019)</span> and the next footnote.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>In addition to Dorst’s argument, see <span class="citation" data-cites="easwaran:2016b">Easwaran (2016)</span>, <span class="citation" data-cites="easwaran-fitelson:2015">Easwaran and Fitelson (2015)</span> and <span class="citation" data-cites="pettigrew:2016c">Pettigrew (2016b)</span> for similar arguments in favour of the conservative account of epistemic value. See <span class="citation" data-cites="steinberger_f:2019a">Steinberger (2019)</span> on why alternatives to conservatism are compatible with accuracy-first epistemology.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>Similar arguments can be found in <span class="citation" data-cites="easwaran:2016b">Easwaran (2016§B)</span> and <span class="citation" data-cites="pettigrew:2016c">Pettigrew (2016b, 256)</span>. <span class="citation" data-cites="dorst:2019">Dorst (2019, 31 — esp. proposition 3)</span> argues for a similar but contextualist view.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p>Elsewhere, <span class="citation" data-cites="kolodny:2005">Kolodny (2005)</span> raises some objections against the normativity of other structural requirements, such as Inter-Level Coherence.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12" role="doc-endnote"><p>See notably <span class="citation" data-cites="goldman_ai:2015a">Goldman (2015)</span> and <span class="citation" data-cites="whiting_da:2010a">Whiting (2010)</span> on veritism.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13" role="doc-endnote"><p>I thank a reviewer for inviting me to discuss this possibility.<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14" role="doc-endnote"><p>See <span class="citation" data-cites="parfit:2011">Parfit (2011, 144–48)</span> on this distinction.<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15" role="doc-endnote"><p>I thank a reviewer for inviting me to clarify this possibility.<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16" role="doc-endnote"><p>See <span class="citation" data-cites="snedegar_j:2018">Snedegar (2018)</span> for more details.<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17" role="doc-endnote"><p>I thank a referee for inviting me to discuss this objection.<a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18" role="doc-endnote"><p>My response might not convince some readers. In any case, we can draw a lesson from this discussion. We have learned that the expression “a reason to be consistent” is ambiguous. Some readings of this expression are a problem for Kolodny’s argument, and other readings of this expression conflict with vindicating Normativity+.<a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19" role="doc-endnote"><p>I thank a reviewer for bringing this objection to my attention.<a href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
